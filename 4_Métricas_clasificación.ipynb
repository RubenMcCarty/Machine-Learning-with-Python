{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubenMcCarty/Machine-Learning-with-Python/blob/master/4_Me%CC%81tricas_clasificacio%CC%81n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygxPJER8zUyp"
      },
      "source": [
        "# M√©tricas para Clasificaci√≥n Binaria\n",
        "## [M.Sc. Ruben Quispe](https://www.linkedin.com/in/ruben-quispe-l/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6XG5KnAzUyp"
      },
      "source": [
        "En clases anteriores hemos visto como podemos implementar modelos lineales para clasficaci√≥n binaria, ejemplos de los modelos m√°s simples en el `Machine Learning` pero no por ello menos usados (pese a las limitaciones que ya hemos comentado, estos modelos son eficientes y explicables, lo cual es preferido en multitud de aplicaciones). En este clase vamos a ver algunas de las m√©tricas m√°s utilizadas en clasificaci√≥n binaria (aunque pueden extenderse tambi√©n a clasificaci√≥n en varias clases). Estas m√©tricas nos van a ser muy √∫tiles para caracterizar el desempe√±o de nuestros modelos y comparar diferentes modelos entre s√≠ para, por ejemplos, utilizar el mejor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZlQTzaazUyq"
      },
      "source": [
        "## El dataset MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUDl4oK8zUyq"
      },
      "source": [
        "En las clases anteriores sobre clasificaci√≥n binaria hemos trabajado con el dataset Iris para clasificaci√≥n de flores a partir de caracter√≠sticas como el ancho o la longitud de sus p√©talos. En este post vamos a utilizar un nuevo dataset, probablemente el m√°s utilizado mientras aprendemos sobre `Deep Learning` y considerado el *hello world* del `Machine Learning`: el dataset [MNIST](http://yann.lecun.com/exdb/mnist/). Este dataset fue elaborado con el objetivo de entrenar modelos autom√°ticos de OCR (*Optical Character Recognition*) para poder acelerar el trabajo de clasificaci√≥n de correo a partir del c√≥digo postal escrito. Est√° formado por 70,0000 im√°genes de d√≠gitos manuscritos, entre $0$ y $9$, y el objetivo es el de ser capaces de dise√±ar un algoritmo capaz de clasificar una im√°gen (decir que n√∫mero es) directamente a partir de sus pixeles. De entre las diferentes fuentes que podemos utilizar para descargar estos datos, vamos a utilizar [Scikit-Learn](https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:30.332724Z",
          "start_time": "2020-07-14T11:34:11.690776Z"
        },
        "id": "Cbv_Gf5TzUyr",
        "outputId": "daa92e1a-6d94-4f83-ed3c-c90091d162b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "mnist.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:30.348758Z",
          "start_time": "2020-07-14T11:34:30.333725Z"
        },
        "id": "KWX7asI_zUys",
        "outputId": "eabb6788-ffbb-419c-df18-e15a78a347e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((70000, 784), (70000,))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHwY8YEyzUys"
      },
      "source": [
        "Como puedes ver, cada im√°gen est√° formada por $784$ caracter√≠sticas (los pixeles). Podemos visualizar unas cuantas im√°genes junto a sus etiquetas de la siguiente manera para hacernos una idea del tipo de datos al que nos enfrentamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:30.906759Z",
          "start_time": "2020-07-14T11:34:30.349757Z"
        },
        "id": "B-ze4oZEzUyt",
        "outputId": "1367901b-f2bf-4097-fbc6-0e1838d6a63f"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "63745",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 63745",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-824e99cbb58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 63745"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "\n",
        "r, c = 3, 5\n",
        "fig = plt.figure(figsize=(2*c, 2*r))\n",
        "for _r in range(r):\n",
        "    for _c in range(c):\n",
        "        plt.subplot(r, c, _r*c + _c + 1)\n",
        "        ix = random.randint(0, len(X)-1)\n",
        "        img = X[ix]\n",
        "        plt.imshow(img.reshape(28,28), cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(y[ix])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvasSJ5-k9CS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZyFKjepzUyu"
      },
      "source": [
        "Por √∫ltimo, vamos a extraer $60,000$ im√°genes para entrenar nuestro modelo y $10,000$ para evaluarlo y calcular las diferentes m√©tricas que veremos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.016284Z",
          "start_time": "2020-07-14T11:34:30.907761Z"
        },
        "id": "H1yTBFXYzUyu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000] / 255., X[60000:] / 255., y[:60000], y[60000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIL-01vbzUyu"
      },
      "source": [
        "> üí° Recuerda que para que nuestro modelo pueda aprender mejor tenemos que normalizar los datos que usaremos como entrada. En este caso cada p√≠xel est√° representado por un valor entero entre 0-255, por lo que al dividir cada im√°gen por 255 nos aseguramos que nuestros valores a la entrada est√©n en el rango 0-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T09:09:07.216330Z",
          "start_time": "2020-07-14T09:09:07.203298Z"
        },
        "id": "XRNLzUr5zUyu"
      },
      "source": [
        "## Entrenando un clasificador binario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ebPOEJhzUyv"
      },
      "source": [
        "Para llevar a cabo una tarea de clasificaci√≥n binaria necesitamos que nuestro dataset est√© dividido en dos clases, sin embargo el dataset MNIST, c√≥mo ya hemos visto, tiene $10$ clases (todos los d√≠gitos entre $0$ y $9$). En este caso vamos entrenar un modelo para clasificar las im√°genes con el n√∫mero $5$ del resto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.032283Z",
          "start_time": "2020-07-14T11:34:31.017285Z"
        },
        "id": "cF3peFb6zUyv",
        "outputId": "99600896-6a77-4b33-c1bc-59c21c047de2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-1e29965138a2>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_train_5 = (y_train == '5').astype(np.int)\n",
            "<ipython-input-9-1e29965138a2>:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_test_5 = (y_test == '5').astype(np.int)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_train_5 = (y_train == '5').astype(np.int)\n",
        "y_test_5 = (y_test == '5').astype(np.int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWTC9-qSzUyv"
      },
      "source": [
        "Y ahora traemos el modelo de Regresi√≥n Log√≠stica que implementamos en el [post](https://sensioai.com/blog/015_logistic_regression) anterior. Si no est√°s familiarizado con este modelo te recomiendo que le eches un vistazo al post antes de seguir. En este caso hemos cambiado el esquema de inicializaci√≥n de los pesos, utilizando una distribuci√≥n normal escalada por el n√∫mero de pesos. Tambi√©n hemos a√±adido un `print` para ver c√≥mo va evolucionando el modelo durante el entrenamiento, visualizando el valor de la *loss function* en cada *epoch*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.047282Z",
          "start_time": "2020-07-14T11:34:31.033284Z"
        },
        "code_folding": [],
        "id": "5_OoM3_gzUyv"
      },
      "outputs": [],
      "source": [
        "def bce(y, y_hat):\n",
        "    return - np.mean(y*np.log(y_hat) - (1 - y)*np.log(1 - y_hat))\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Perceptron():\n",
        "  def __init__(self, size):\n",
        "    self.w = np.random.normal(loc=0.0, \n",
        "          scale = np.sqrt(2/(size+1)), \n",
        "          size = (size, )) \n",
        "    self.ws = []\n",
        "    self.activation = sigmoid\n",
        "    self.loss = bce\n",
        "    \n",
        "  def __call__(self, w, x):\n",
        "    return self.activation(np.dot(x, w)) \n",
        "\n",
        "  def fit(self, x, y, epochs, lr, verbose=True):\n",
        "    x = np.c_[np.ones(len(x)), x]\n",
        "    for epoch in range(1,epochs+1):\n",
        "        # Batch Gradient Descent\n",
        "        y_hat = self(self.w, x)  \n",
        "        # funci√≥n de p√©rdida\n",
        "        l = self.loss(y, y_hat)\n",
        "        # derivadas\n",
        "        dldh = (y_hat - y)\n",
        "        dhdw = x\n",
        "        dldw = np.dot(dldh, dhdw)\n",
        "        # actualizar pesos\n",
        "        self.w = self.w - lr*dldw\n",
        "        # guardar pesos para animaci√≥n\n",
        "        self.ws.append(self.w.copy())\n",
        "        # print loss\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch}/{epochs} Loss {l}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.706966Z",
          "start_time": "2020-07-14T11:34:31.049283Z"
        },
        "id": "Lm_JgNITzUyw",
        "outputId": "5c850ab4-b6cc-41a1-c736-28602541117c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 Loss -0.5548410142855111\n",
            "Epoch 2/10 Loss 0.7206598224991337\n",
            "Epoch 3/10 Loss 0.5304482677090383\n",
            "Epoch 4/10 Loss 0.33874121387580547\n",
            "Epoch 5/10 Loss 0.1481787367177453\n",
            "Epoch 6/10 Loss 0.029990518845371003\n",
            "Epoch 7/10 Loss 0.07018573941348813\n",
            "Epoch 8/10 Loss 0.03957115693418078\n",
            "Epoch 9/10 Loss 0.05379890044402431\n",
            "Epoch 10/10 Loss 0.041989565540281604\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "perceptron = Perceptron(X.shape[1] + 1)\n",
        "epochs, lr = 10, 1e-5\n",
        "perceptron.fit(X_train, y_train_5, epochs, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0PPYFSezUyw"
      },
      "source": [
        "En este punto ya hemos entrenado nuestro modelo. Ahora, ¬øc√≥mo lo podemos evaluar? ¬øEs este un buen modelo o un mal modelo? ¬øSi entrenamos otro modelo, c√≥mo podemos saber si es mejor o pero que el primero? Todas estas preguntas las podemos responder con las `m√©tricas`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6gN1w_DzUyw"
      },
      "source": [
        "## M√©tricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYY4PN7ZzUyw"
      },
      "source": [
        "Vamos a ver las m√©tricas m√°s utilizadas en la evaluaci√≥n de modelos de clasificaci√≥n binaria. Para calcular cualquier m√©trica vamos a necesitar ser capaces de generar predicciones con nuestro modelo. En posts anterior ya hemos visto c√≥mo podemos hacerlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.722963Z",
          "start_time": "2020-07-14T11:34:31.707968Z"
        },
        "id": "1wlh3JiUzUyw"
      },
      "outputs": [],
      "source": [
        "def evaluate(perceptron, x, t = 0.5):\n",
        "    w = perceptron.ws[-1]\n",
        "    x = np.c_[np.ones(len(x)), x]\n",
        "    y = perceptron(w, x)\n",
        "    return (y > t).astype(np.int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3gDBixIzUyw"
      },
      "source": [
        "### *Accuracy*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScCn1A3ZzUyw"
      },
      "source": [
        "La primera m√©trica que vamos a ver, tambi√©n la m√°s com√∫n, es la *accuracy* (o precisi√≥n). En esta m√©trica simplemente contamos todos los elementos del dataset que nuestro modelo ha sido capaz de clasificar correctamente y lo dividimos entre el n√∫mero total de elementos. √âsto implica que la precisi√≥n ser√° un valor entre $0$ y $1$, significando $0$ que nuestro modelo no ha acertado ning√∫n resultado y $1$ que los ha acertado todos. Tambi√©n es com√∫n dar este valor en porcentaje (simplemente multiplicando por $100$ el resultado anterior)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.738962Z",
          "start_time": "2020-07-14T11:34:31.723965Z"
        },
        "id": "a9Ib-WHPzUyx"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred, y):\n",
        "    return np.sum(y_pred == y) / len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.880965Z",
          "start_time": "2020-07-14T11:34:31.739962Z"
        },
        "id": "hiCpe2xEzUyx",
        "outputId": "24c767a3-2cba-47da-906a-1e6f6fe7916c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-7df743ea669f>:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  return (y > t).astype(np.int)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9196666666666666"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = evaluate(perceptron, X_train)\n",
        "accuracy(y_pred, y_train_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.912963Z",
          "start_time": "2020-07-14T11:34:31.881965Z"
        },
        "id": "_s_9wzBazUyx",
        "outputId": "fffe9d21-839a-4ae0-a87f-fe6826908699"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-7df743ea669f>:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  return (y > t).astype(np.int)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9232"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = evaluate(perceptron, X_test)\n",
        "accuracy(y_pred, y_test_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNdG3q0PzUyx"
      },
      "source": [
        "C√≥mo podemos ver nuestro modelo tiene una precisi√≥n cercana al $92 \\%$ tanto para el conjunto de entrenamiento como para el de evaluaci√≥n. ¬øEs este un buen modelo? A priori podr√≠amos pensar que si, ya que nuestro modelo acierta $9$ de cada $10$ im√°genes... Sin embargo, la realidad es que nuestro modelo no est√° haciendo pr√°cticamente nada. Vamos a ver porqu√© analizando nuestros datos. C√≥mo ya hemos comentado estamos haciendo un clasificador binario para detectar el n√∫mero $5$. ¬øCu√°ntas im√°genes diferentes de $5$s tenemos en nuestro dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:31.928962Z",
          "start_time": "2020-07-14T11:34:31.913963Z"
        },
        "id": "IxWJg-UKzUyx",
        "outputId": "fe83fdb8-0769-45b1-b3c0-746185ad89ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.90965, 0.9108)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1 - y_train_5.mean(), 1 - y_test_5.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmNviOFozUyx"
      },
      "source": [
        "Aqu√≠ tenemos la respuesta, nuestro dataset est√° formado en un $91 \\%$ por im√°genes que no son $5$. Esto significa que un modelo *naive* que siempre diga que NO tenemos un $5$ va a tener una *accuracy* del $91 \\%$. Sin embargo, en el mundo real, nunca detectaremos este d√≠gito y nuestra aplicaci√≥n fallar√° estrepitosamente. Nuestro modelo tiene una precisi√≥n del $92 \\%$, mejorando ligreamente este valor pero no por mucho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:32.447968Z",
          "start_time": "2020-07-14T11:34:31.929963Z"
        },
        "id": "1EVu9KwgzUyx"
      },
      "outputs": [],
      "source": [
        "r, c = 3, 5\n",
        "fig = plt.figure(figsize=(2*c, 2*r))\n",
        "for _r in range(r):\n",
        "    for _c in range(c):\n",
        "        plt.subplot(r, c, _r*c + _c + 1)\n",
        "        fives = (y_test_5 == 1)\n",
        "        ix = random.randint(0, len(X_test[fives])-1)\n",
        "        img = X_test[fives][ix]\n",
        "        plt.imshow(img.reshape(28,28), cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "        y_pred = evaluate(perceptron, [img])\n",
        "        plt.title(f\"{y_test_5[fives][ix]} / {y_pred[0]}\", color=\"red\" if y_test_5[fives][ix] != y_pred[0] else \"green\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVOnm-8WzUyx"
      },
      "source": [
        "Como puedes ver la m√©trica de precisi√≥n es muy √∫til pero puede llevar a enga√±os. Esto se hace especialmente patente en aplicaciones en las que tenemos muy pocas muestras de la clase que queremos capturar. Un ejemplo claro es el de detecci√≥n de transacciones bancarias fraudulentas, que representan cerca del 0.001% del total de operaciones realizadas. Un modelo de clasificaci√≥n binaria que siempre diese como resultado que una transacci√≥n NO es fraudulenta tendr√≠a una precisi√≥n del 99.999%, sin embargo ser√≠a un modelo totalmente in√∫til en el mundo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMlQHRBWzUyx"
      },
      "source": [
        "> ‚ö° Siempre es recomendable tener unas primeras m√©tricas `baseline` con las que comparar nuestros modelos. Estas m√©tricas pueden obtenerse con un modelo aleatorio (antes de ser entrenado) o en el caso de la clasificaci√≥n podemos utilizar directamente la distribuci√≥n de clases en el dataset. Cualquier modelo que hagamos deber√≠a mejorar estas m√©tricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR6OIrAnzUyx"
      },
      "source": [
        "En este caso en particular podemos obtener un mejor modelo simplemente entrenando durante m√°s epochs (el modelo anterior no hab√≠a convergido)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:48.937986Z",
          "start_time": "2020-07-14T11:34:32.448966Z"
        },
        "id": "oNC3TZp9zUyx"
      },
      "outputs": [],
      "source": [
        "perceptron = Perceptron(X.shape[1] + 1)\n",
        "epochs, lr = 300, 1e-5\n",
        "perceptron.fit(X_train, y_train_5, epochs, lr, verbose=False)\n",
        "y_pred = evaluate(perceptron, X_test)\n",
        "accuracy(y_pred, y_test_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:49.525005Z",
          "start_time": "2020-07-14T11:34:48.938989Z"
        },
        "id": "7q0avm2GzUyy"
      },
      "outputs": [],
      "source": [
        "r, c = 3, 5\n",
        "fig = plt.figure(figsize=(2*c, 2*r))\n",
        "for _r in range(r):\n",
        "    for _c in range(c):\n",
        "        plt.subplot(r, c, _r*c + _c + 1)\n",
        "        fives = (y_test_5 == 1)\n",
        "        ix = random.randint(0, len(X_test[fives])-1)\n",
        "        img = X_test[fives][ix]\n",
        "        plt.imshow(img.reshape(28,28), cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "        y_preds = evaluate(perceptron, [img])\n",
        "        plt.title(f\"{y_test_5[fives][ix]} / {y_preds[0]}\", color=\"red\" if y_test_5[fives][ix] != y_preds[0] else \"green\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mucX0O8YzUyy"
      },
      "source": [
        "Todas las m√©tricas que vamos a ver est√°n implementadas en la librer√≠a `Scikit Learn`, por lo que te recomiendo que las uses directamente para evitar errores en la implementaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:49.555999Z",
          "start_time": "2020-07-14T11:34:49.526005Z"
        },
        "id": "46EUhKkyzUyy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_test_5, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zu1-BzszUyy"
      },
      "source": [
        "### La Matriz de Confusi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShGzmOK9zUyy"
      },
      "source": [
        "Una matriz de confusi√≥n nos va a indicar exactamente cuales son los puntos fuertes y d√©biles de nuestro clasificador. Para cada clase, vamos a calcular cuantos elementos han sido bien clasificados por nuestro modelo y cu√°ntos han sido confundidos con otras clases (esta matriz nos ser√° muy √∫til en clasificaci√≥n en varias clases tambi√©n)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:49.571999Z",
          "start_time": "2020-07-14T11:34:49.556999Z"
        },
        "id": "HxN14FWwzUyy"
      },
      "outputs": [],
      "source": [
        "TP = np.sum((y_pred == 1) & (y_test_5 == 1)) \n",
        "TN = np.sum((y_pred == 0) & (y_test_5 == 0)) \n",
        "FP = np.sum((y_pred == 1) & (y_test_5 == 0))\n",
        "FN = np.sum((y_pred == 0) & (y_test_5 == 1))\n",
        "\n",
        "CM = [[TN, FP],\n",
        "      [FN, TP]]\n",
        "CM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V92brzDzUyy"
      },
      "source": [
        "En esta matriz podemos observar:\n",
        "    \n",
        "- Verdaderos Positivos (TP, *True Positives*): elementos que nuestro modelo clasifica correctamente como la clase que nos interesa, la clase positiva (fila 1, columna 1).\n",
        "- Verdaderos Negativos (TN, *True Negatives*): elementos que nuestro modelo clasifica correctamente como la clase negativa (fila 0, columna 0).\n",
        "- Falsos Positivos (FP, *False Positives*): elementos que nuestro modelo clasifica err√≥neamente como la clase positiva (fila 0, columna 1).\n",
        "- Falsos Negativos (FN, *False Negatives*): elementos que nuestro modelo clasifica err√≥neamente como la clase negativa (fila 1, columna 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:49.587999Z",
          "start_time": "2020-07-14T11:34:49.572999Z"
        },
        "id": "YnINkm4LzUyy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test_5, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QopQe1OgzUyy"
      },
      "source": [
        "> üí° Una vez vistos los conceptos definidos en este apartado podemos reescribir la *accuracy* como $ accuracy = \\frac{TP + TN}{TP+TN+FP+FN} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcHTgviJzUyy"
      },
      "source": [
        "### *Precision* y *Recall*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rprLcS_szUyz"
      },
      "source": [
        "Hemos visto la confusi√≥n a la que nos puede llevar una m√©trica simple como la *accuracy*. Ahora veremos dos m√©tricas que un poco m√°s informativas. √âstas son *precision* (no confundir con la precisi√≥n, en castellano, equivalente a la *accuracy*) y *recall*. Para definir estas m√©tricas primero necesitamos definir los siguiente conceptos:\n",
        "\n",
        "$$ precision = \\frac{TP}{TP+FP} $$\n",
        "\n",
        "$$ recall = \\frac{TP}{TP+FN} $$\n",
        "\n",
        "En la siguiente im√°gen puedes ver una visualizaci√≥n de estas m√©tricas. *Precision* nos da una idea de c√≥mo de propenso es nuestro modelo a dar falsos positivos. Un valor cercano a $1$ indicar√° que nuestro modelo apenas da falsos positivos (aunque puede seguir fallando dando falsos negativos) mientras que un valor cercano a $0$ indicar√° que nuestro modelo da muchos falsos positivos. Lo mismo aplica al *Recall*, pero en este caso aplicada a los falsos negativos. Un valor cercano a $1$ indicar√° que nuestro modelo apenas da falsos negativos (aunque puede seguir fallando dando falsos positivos) mientras que un valor cercano a $0$ indicar√° que nuestro modelo da muchos falsos negativos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T10:17:58.102236Z",
          "start_time": "2020-07-14T10:17:58.050344Z"
        },
        "id": "Xj194QFQzUyz"
      },
      "source": [
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:49.604000Z",
          "start_time": "2020-07-14T11:34:49.588999Z"
        },
        "id": "oYQbChldzUyz"
      },
      "outputs": [],
      "source": [
        "def precision(y_pred, y):\n",
        "    TP = np.sum((y_pred == 1) & (y == 1)) \n",
        "    FP = np.sum((y_pred == 1) & (y == 0))\n",
        "    return TP / (TP + FP)\n",
        "\n",
        "def recall(y_pred, y):\n",
        "    TP = np.sum((y_pred == 1) & (y == 1)) \n",
        "    FN = np.sum((y_pred == 0) & (y == 1))\n",
        "    return TP / (TP + FN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:49.636000Z",
          "start_time": "2020-07-14T11:34:49.605003Z"
        },
        "id": "LMm1ix52zUyz"
      },
      "outputs": [],
      "source": [
        "y_pred = evaluate(perceptron, X_test)\n",
        "precision(y_pred, y_test_5), recall(y_pred, y_test_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:49.652002Z",
          "start_time": "2020-07-14T11:34:49.637999Z"
        },
        "id": "CFiPUbltzUyz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision_score(y_test_5, y_pred), recall_score(y_test_5, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtbYyvShzUyz"
      },
      "source": [
        "En funci√≥n de la aplicaci√≥n en la que estemos trabajando vamos a querer optimizar una m√©trica u otra. En aplicaciones en las que tener falsos positivos sea perjudicial (por ejemplo, aplicaciones de seguridad) querremos modelos con un buena *precision*, mientras que en aplicaciones en las que tener falsos negativos sea perjudicial (por ejemplo, sistemas de diagn√≥stico m√©dico) querremos modelos con buen *recall*. Una vez nuestro modelo ha sido entrenado, podemos ajustar estas m√©tricas variando el valor del *threshold* utilizado en la evaluaci√≥n. A esto se le conoce como el *precision-recall trade off*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:50.082002Z",
          "start_time": "2020-07-14T11:34:49.654000Z"
        },
        "id": "6pPkVhXmzUyz"
      },
      "outputs": [],
      "source": [
        "for t in np.linspace(0.1,0.9,20):\n",
        "    y_pred = evaluate(perceptron, X_test, t)\n",
        "    print(f\"Threshold: {t:.3f} Precision {precision(y_pred, y_test_5):.4f} Recall {recall(y_pred, y_test_5):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPnHJFb1zUyz"
      },
      "source": [
        "C√≥mo se puede observar, incrementar el valor de una de las m√©tricas implica que la otra va a disminuir (es por esto que se le llama *trade-off* ya que tenemos que llegar a un compromiso). As√≠ pues, escogeremos un valor del *threshold* que se ajusto a los criterios de dise√±o de nuestra aplicaci√≥n en particular (en funci√≥n de la cantidad de falsos positivos y falsos negativos que estemos dispuestos a asumir)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T10:45:15.188117Z",
          "start_time": "2020-07-14T10:45:15.144035Z"
        },
        "id": "0RjK-rRPzUyz"
      },
      "source": [
        "![](https://wizardforcel.gitbooks.io/scikit-and-tensorflow-workbooks-bjpcjp/pics/decision-threshold-and-precision-vs-recall.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7aXfZOlzUyz"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckmUYCdBzUyz"
      },
      "source": [
        "Una m√©trica r√°pida que nos va a decir si nuestro modelo tiene buena *precision* y *recall* es el *F1-score*.\n",
        "\n",
        "$$  F_1 = 2 \\times \\frac{precision \\times recall}{precision + recall} $$\n",
        "\n",
        "Es una m√©trica muy usada ya que aglutina la informaci√≥n de ambas m√©tricas, sin embargo va a favorecer mucho aquellos modelos con un valor similar de *precision* y *recall*, lo cual ya hemos comentado que no es siempre lo que vamos a querer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:50.114041Z",
          "start_time": "2020-07-14T11:34:50.083004Z"
        },
        "id": "QFfwMuxqzUyz"
      },
      "outputs": [],
      "source": [
        "y_pred = evaluate(perceptron, X_test)\n",
        "\n",
        "p = precision_score(y_test_5, y_pred)\n",
        "r = recall_score(y_test_5, y_pred)\n",
        "\n",
        "f1 = 2*(p*r)/(p+r)\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:50.130040Z",
          "start_time": "2020-07-14T11:34:50.115041Z"
        },
        "id": "U7Vdj-8AzUyz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_test_5, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ocZ9E5DzUyz"
      },
      "source": [
        "### La curva ROC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAx-VjFJzUy0"
      },
      "source": [
        "Podemos visualizar r√°pidamente el comportamiento de un modelo para varios *thresholds* con la llamada curva ROC (*Receiver Operating Characteristic*). En ella representamos el ratio de verdaderos positivos (TPR) contra el ratio de falsos positivos (FPR), definidos de la siguiente manera:\n",
        "\n",
        "$$ TPR = \\frac{TP}{TP+FN} $$\n",
        "\n",
        "$$ FPR = \\frac{FP}{FP+TN} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:50.145040Z",
          "start_time": "2020-07-14T11:34:50.131040Z"
        },
        "id": "VSkDtbpwzUy0"
      },
      "outputs": [],
      "source": [
        "def evaluate2(perceptron, x):\n",
        "    w = perceptron.ws[-1]\n",
        "    x = np.c_[np.ones(len(x)), x]\n",
        "    y = perceptron(w, x)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:50.176040Z",
          "start_time": "2020-07-14T11:34:50.146040Z"
        },
        "id": "8FEnL3wDzUy0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_pred2 = evaluate2(perceptron, X_test)\n",
        "fpr, tpr, thresholds = roc_curve(y_test_5, y_pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:50.272041Z",
          "start_time": "2020-07-14T11:34:50.177040Z"
        },
        "id": "uj0_sVQ4zUy0"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'k--') \n",
        "    plt.axis([0, 1, 0, 1])                                    \n",
        "    plt.xlabel('FPR', fontsize=16) \n",
        "    plt.ylabel('TPR', fontsize=16)    \n",
        "    plt.grid(True)                                            \n",
        "\n",
        "plt.figure(figsize=(8, 6))                         \n",
        "plot_roc_curve(fpr, tpr)              \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTzUjDGIzUy0"
      },
      "source": [
        "Una m√©trica muy utilizada para comparar clasificadores es el √°rea bajo la curva ROC, ya que nos indica como de robusto es un modelo. La l√≠nea recta representa un modelo *naive* que podemos usar como baseline. C√≥mo puedes ver el √°rea bajo la curva ROC de este modelo es de $0.5$, por lo que cualquier modelo que hagamos deber√≠a superar este valor. Cu√°nto m√°s se acerque la curva a la esquina superior izquierda, mayor ser√° el √°rea y mejor ser√° el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-14T11:34:50.288041Z",
          "start_time": "2020-07-14T11:34:50.273041Z"
        },
        "id": "NfmbUDd1zUy0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_test_5, y_pred2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh4FxbQnzUy0"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kO7kAMXzUy0"
      },
      "source": [
        "En este post hemos visto las m√©tricas m√°s comunes cuando trabajamos con clasificadores (tanto binarios como multi-clase). Para ello hemos trabajado con el dataset MNIST, uno de los datasets m√°s utilizados en el `Machine Learning`. El objetivo es el de clasificar im√°genes de d√≠gitos manuscritos en 10 clases (desde el d√≠gito 0 al 9), sin embargo lo hemos adaptado para hacer clasificaci√≥n binaria de im√°genes con el n√∫mero 5. Tambi√©n hemos mejorado ligeramente la implementaci√≥n de nuestro `Perceptr√≥n` con una mejor inicializaci√≥n de los pesos y la posibilidad de visualizar la evoluci√≥n de la funci√≥n de p√©rdida durante el entrenamiento. Despu√©s hemos visto las siguiente m√©tricas:\n",
        "\n",
        "- *Accuracy* es la m√°s simple, consistente en contar cuantos elementos del dataset nuestro modelo clasifica correctamente. Puede llevarnos a enga√±os si no tenemos en cuenta la distribuci√≥n de nuestras clases, poniendo en relevancia la necesidad de tener m√©tricas `baseline` para comprar nuestros primeros modelos.\n",
        "- La matriz de confusi√≥n nos va indicar el n√∫mero de elementos del nuestro dataset que el modelo clasifica bien, as√≠ como todos los que confunda con otras clases. De esta manera sabremos c√≥mo mejorar nuestro modelo.\n",
        "- *Precision* y *Recall* nos indican c√≥mo de robusto ser√° nuestro modelo, cuantificando los falsos positivos y falsos negativos. En funci√≥n de nuestra aplicaci√≥n y su sensibilidad preferiremos una mejor m√©trica u otra (como hemos visto, mejorar una de ella implica empeorar la otra).\n",
        "- El *F1-Score* nos dar√° una idea r√°pida de la robustez del modelo combinando las dos m√©tricas anteriores.\n",
        "- La curva *ROC*, y en especial el √°rea debajo de la curva, ser√° una muy buena manera de comparar modelos para poder elegir el que m√°s se ajuste a nuestras necesidades.\n",
        "\n",
        "Como podemos ver, evaluar un modelo va m√°s all√° de proporcionar un valor de precisi√≥n y depender√° en gran medida de la aplicaci√≥n en cuesti√≥n y las condiciones reales a las que se vaya a enfrentar nuestro modelo en el mundo real. Monitorizar nuestros modelos constantemente nos permitir√° mejorarlos de manera cont√≠nua as√≠ como encontrar posibles fallos, y para ello saber qu√© m√©tricas son las importantes es fundamental."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfOkdIm6zUy0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}